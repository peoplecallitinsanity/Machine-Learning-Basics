# Machine Learning Basics
Welcome to Machine Learning Basics, a collection of Jupyter notebooks covering key topics in machine learning, data analysis, and Python programming. These notebooks serve as a step-by-step guide to essential algorithms and techniques, making it a useful resource for anyone looking to build a strong foundation in machine learning.

## What's Inside
**1. 01_Python_OOP.ipynb**

A notebook covering the fundamentals of Object-Oriented Programming (OOP) in Python.

It includes concepts such as classes, objects, inheritance, and polymorphism, which are useful for structuring machine learning projects.

**2. 02_Pandas.ipynb**

An introduction to pandas, a powerful library for data manipulation.

Topics include handling missing data, filtering, sorting, and performing common data operations with DataFrames.

**3. 02_Pandas_Diabetes.ipynb**

Applies pandas techniques to the Diabetes dataset.

Focuses on data cleaning and exploratory data analysis (EDA) to better understand the dataset.

**4. 03_Numpy.ipynb**

A deep dive into numpy, focusing on array operations, broadcasting, and essential functions for numerical data processing in machine learning.

**5. 04_Linear_Regression.ipynb**

An exploration of Linear Regression, covering both the theoretical background and practical implementation using scikit-learn.

Includes real-world examples for regression tasks.

**6. 05_Logistic_Regression.ipynb**

This notebook explains Logistic Regression for binary classification tasks.

Covers the math behind it, with practical examples implemented in scikit-learn.

**7. 06_PCA_algorithm.ipynb**

A guide to Principal Component Analysis (PCA), a technique for reducing dimensionality in high-dimensional datasets.

Practical applications show how PCA simplifies data while retaining important information.

**8. 08_Naive_Bayes.ipynb**

An introduction to Naive Bayes, a simple but effective classification algorithm.

It walks through the theoretical aspects and provides examples of how to apply Naive Bayes to classification problems, such as text data.

**9. 09_GMM.ipynb**

This notebook covers Gaussian Mixture Models (GMM), a probabilistic model used for clustering.

Explores how to fit GMMs to data and analyze the clustering results.

**10. 10_KMeans.ipynb**

A tutorial on K-Means Clustering, a popular unsupervised learning algorithm.

Learn how to choose the optimal number of clusters and apply K-Means to various datasets.

**11. 11_Model_Interpretation.ipynb**

Focuses on techniques for interpreting machine learning models.

Introduces methods like SHAP and LIME to better understand how models make predictions and why they arrive at certain decisions.

**12. 15_16_ModelInt&HyperpTuning.ipynb**

This notebook explores hyperparameter tuning and model interpretation.

Techniques like Grid Search and Random Search are used to optimize model performance, while interpretation methods ensure transparency.

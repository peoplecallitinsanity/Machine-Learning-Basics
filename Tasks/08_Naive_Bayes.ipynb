{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset into a pandas dataframe\n",
    "df = pd.read_csv('kidney_disease.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>395</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>6700</td>\n",
       "      <td>4.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>396</td>\n",
       "      <td>42.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>54</td>\n",
       "      <td>7800</td>\n",
       "      <td>6.2</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>397</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>6600</td>\n",
       "      <td>5.4</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>7200</td>\n",
       "      <td>5.9</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>399</td>\n",
       "      <td>58.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>6800</td>\n",
       "      <td>6.1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>notckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   age    bp     sg   al   su     rbc        pc         pcc  \\\n",
       "0      0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent   \n",
       "1      1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent   \n",
       "2      2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent   \n",
       "3      3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present   \n",
       "4      4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent   \n",
       "..   ...   ...   ...    ...  ...  ...     ...       ...         ...   \n",
       "395  395  55.0  80.0  1.020  0.0  0.0  normal    normal  notpresent   \n",
       "396  396  42.0  70.0  1.025  0.0  0.0  normal    normal  notpresent   \n",
       "397  397  12.0  80.0  1.020  0.0  0.0  normal    normal  notpresent   \n",
       "398  398  17.0  60.0  1.025  0.0  0.0  normal    normal  notpresent   \n",
       "399  399  58.0  80.0  1.025  0.0  0.0  normal    normal  notpresent   \n",
       "\n",
       "             ba  ...  pcv    wc   rc  htn   dm  cad appet   pe  ane  \\\n",
       "0    notpresent  ...   44  7800  5.2  yes  yes   no  good   no   no   \n",
       "1    notpresent  ...   38  6000  NaN   no   no   no  good   no   no   \n",
       "2    notpresent  ...   31  7500  NaN   no  yes   no  poor   no  yes   \n",
       "3    notpresent  ...   32  6700  3.9  yes   no   no  poor  yes  yes   \n",
       "4    notpresent  ...   35  7300  4.6   no   no   no  good   no   no   \n",
       "..          ...  ...  ...   ...  ...  ...  ...  ...   ...  ...  ...   \n",
       "395  notpresent  ...   47  6700  4.9   no   no   no  good   no   no   \n",
       "396  notpresent  ...   54  7800  6.2   no   no   no  good   no   no   \n",
       "397  notpresent  ...   49  6600  5.4   no   no   no  good   no   no   \n",
       "398  notpresent  ...   51  7200  5.9   no   no   no  good   no   no   \n",
       "399  notpresent  ...   53  6800  6.1   no   no   no  good   no   no   \n",
       "\n",
       "    classification  \n",
       "0              ckd  \n",
       "1              ckd  \n",
       "2              ckd  \n",
       "3              ckd  \n",
       "4              ckd  \n",
       "..             ...  \n",
       "395         notckd  \n",
       "396         notckd  \n",
       "397         notckd  \n",
       "398         notckd  \n",
       "399         notckd  \n",
       "\n",
       "[400 rows x 26 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Visualising our dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "age                 9\n",
       "bp                 12\n",
       "sg                 47\n",
       "al                 46\n",
       "su                 49\n",
       "rbc               152\n",
       "pc                 65\n",
       "pcc                 4\n",
       "ba                  4\n",
       "bgr                44\n",
       "bu                 19\n",
       "sc                 17\n",
       "sod                87\n",
       "pot                88\n",
       "hemo               52\n",
       "pcv                70\n",
       "wc                105\n",
       "rc                130\n",
       "htn                 2\n",
       "dm                  2\n",
       "cad                 2\n",
       "appet               1\n",
       "pe                  1\n",
       "ane                 1\n",
       "classification      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying isna() to our dataframe to see how many missing values we have\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can get rid of rows with minimum missing values from certain columns \n",
    "df = df.dropna(subset = ['htn','dm', 'cad', 'appet', 'pe','ane'])\n",
    "df = df.dropna(subset = ['pcc','ba', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing text-values with numbers ( 1 for yes/positive, 0 for no/negative) \n",
    "df['rbc'] = df['rbc'].map({'normal' : 1, 'abnormal' : 0})\n",
    "df['pc'] = df['pc'].map({'normal' : 1, 'abnormal' : 0})\n",
    "df['pcc'] = df['pcc'].map({'present' : 1, 'notpresent' : 0})\n",
    "df['ba'] = df['ba'].map({'present' : 1, 'notpresent' : 0})\n",
    "df['htn'] = df['htn'].map({'yes' : 1, 'no' : 0})\n",
    "df['dm'] = df['dm'].map({'yes' : 1, 'no' : 0, '\\tno' : 0, '\\tyes' : 1})\n",
    "df['cad'] = df['cad'].map({'yes' : 1, 'no' : 0, '\\tno' : 0})\n",
    "df['appet'] = df['appet'].map({'good' : 1, 'poor' : 0})\n",
    "df['pe'] = df['pe'].map({'yes' : 1, 'no' : 0})\n",
    "df['ane'] = df['ane'].map({'yes' : 1, 'no' : 0})\n",
    "#Replacing our y columns' values ( 1 for checked and 0 for not checked)\n",
    "df['classification'] = df['classification'].map({'ckd' : 1, 'notckd' : 0, 'ckd\\t' : 0})\n",
    "#Replacing some text values with NaN\n",
    "df['pcv'] = df['pcv'].replace(['\\t43','\\t?'], [43, np.NaN])\n",
    "df['wc'] = df['wc'].replace(['\\t?'], [ np.NaN])\n",
    "df['rc'] = df['rc'].replace(['\\t?'], [ np.NaN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping id column\n",
    "df = df.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the feature matrix and target vector\n",
    "X = df.drop(['classification'], axis=1).values\n",
    "y = df['classification'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantianting the 3 algorithms we will use later, Naive Bayes, Logisitic Regression, KNN\n",
    "gauss = GaussianNB()\n",
    "log_reg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Imputer with mean as strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Instantiating Simple Imputer with mean as strategy, applying fit_transform to train data and transform to test data\n",
    "si_mean = SimpleImputer(strategy = \"mean\")\n",
    "X_train_fill = si_mean.fit_transform(X_train)\n",
    "X_test_fill = si_mean.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next wee will train each of our 3 algorithms on filled values, predicting on test filled values and getting accuracy score for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gauss.fit(X_train_fill, y_train)\n",
    "y_pred = gauss.predict(X_test_fill)\n",
    "acc_gauss_mean = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression algorithm,\n",
    "log_reg.fit(X_train_fill, y_train)\n",
    "y_pred = log_reg.predict(X_test_fill)\n",
    "acc_log_reg_mean = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm, training on filled values, predicting on test filled values and getting accuracy score\n",
    "knn.fit(X_train_fill, y_train)\n",
    "y_pred = knn.predict(X_test_fill)\n",
    "acc_knn_mean = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Imputer with median as strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating Simple Imputer with median as strategy, applying fit_transform to train data and transform to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_median = SimpleImputer(strategy = \"median\")\n",
    "X_train_fill = si_median.fit_transform(X_train)\n",
    "X_test_fill = si_median.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training each of our 3 algorithms on filled values, predicting on test filled values and getting accuracy score for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gauss.fit(X_train_fill, y_train)\n",
    "y_pred = gauss.predict(X_test_fill)\n",
    "acc_gauss_median = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression algorithm\n",
    "log_reg.fit(X_train_fill, y_train)\n",
    "y_pred = log_reg.predict(X_test_fill)\n",
    "acc_log_reg_median = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "knn.fit(X_train_fill, y_train)\n",
    "y_pred = knn.predict(X_test_fill)\n",
    "acc_knn_median = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Imputer with most frequent as strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating Simple Imputer with most frequent as strategy, applying fit_transform to train data and transform to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_most_frequent = SimpleImputer(strategy = \"most_frequent\")\n",
    "X_train_fill = si_most_frequent.fit_transform(X_train)\n",
    "X_test_fill = si_most_frequent.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training each of our 3 algorithms on filled values, predicting on test filled values and getting accuracy score for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gauss.fit(X_train_fill, y_train)\n",
    "y_pred = gauss.predict(X_test_fill)\n",
    "acc_gauss_most_frequent = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression algorithm\n",
    "log_reg.fit(X_train_fill, y_train)\n",
    "y_pred = log_reg.predict(X_test_fill)\n",
    "acc_log_reg_most_frequent = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "knn.fit(X_train_fill, y_train)\n",
    "y_pred = knn.predict(X_test_fill)\n",
    "acc_knn_most_frequent = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Imputer with constant as strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating Simple Imputer with constant as strategy, applying fit_transform to train data and transform to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_constant = SimpleImputer(strategy = \"constant\", fill_value = 0)\n",
    "X_train_fill = si_constant.fit_transform(X_train)\n",
    "X_test_fill = si_constant.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training each of our 3 algorithms on filled values, predicting on test filled values and getting accuracy score for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gauss.fit(X_train_fill, y_train)\n",
    "y_pred = gauss.predict(X_test_fill)\n",
    "acc_gauss_constant = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression algorithm\n",
    "log_reg.fit(X_train_fill, y_train)\n",
    "y_pred = log_reg.predict(X_test_fill)\n",
    "acc_log_reg_constant = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "knn.fit(X_train_fill, y_train)\n",
    "y_pred = knn.predict(X_test_fill)\n",
    "acc_knn_constant = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating Iterative Imputer, applying fit_transform to train data and transform to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\impute\\_iterative.py:701: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "iterative_imputer = IterativeImputer( estimator = LinearRegression())\n",
    "X_train_fill = iterative_imputer.fit_transform(X_train)\n",
    "X_test_fill = iterative_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training each of our 3 algorithms on filled values, predicting on test filled values and getting accuracy score for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gauss.fit(X_train_fill, y_train)\n",
    "y_pred = gauss.predict(X_test_fill)\n",
    "acc_gauss_iterative_imputer = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression algorithm\n",
    "log_reg.fit(X_train_fill, y_train)\n",
    "y_pred = log_reg.predict(X_test_fill)\n",
    "acc_log_reg_iterative_imputer = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "knn.fit(X_train_fill, y_train)\n",
    "y_pred = knn.predict(X_test_fill)\n",
    "acc_knn_iterative_imputer = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating KNN Imputer, applying fit_transform to train data and transform to test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer = KNNImputer()\n",
    "X_train_fill = knn_imputer.fit_transform(X_train)\n",
    "X_test_fill = knn_imputer_pred = knn_imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training each of our 3 algorithms on filled values, predicting on test filled values and getting accuracy score for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes algorithm\n",
    "gauss.fit(X_train_fill, y_train)\n",
    "y_pred = gauss.predict(X_test_fill)\n",
    "acc_gauss_knn_imputer = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pulbe\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression algorithm\n",
    "log_reg.fit(X_train_fill, y_train)\n",
    "y_pred = log_reg.predict(X_test_fill)\n",
    "acc_log_reg_knn_imputer = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN algorithm\n",
    "knn.fit(X_train_fill, y_train)\n",
    "y_pred = knn.predict(X_test_fill)\n",
    "acc_knn_knn_imputer = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A list containing all of our accuracy scores\n",
    "acc_list = [acc_gauss_mean, acc_gauss_median, acc_gauss_most_frequent, acc_gauss_constant, acc_gauss_iterative_imputer, acc_gauss_knn_imputer,acc_log_reg_mean, acc_log_reg_median, acc_log_reg_most_frequent, acc_log_reg_constant, acc_log_reg_iterative_imputer, acc_log_reg_knn_imputer,acc_knn_mean, acc_knn_median, acc_knn_most_frequent, acc_knn_constant, acc_knn_iterative_imputer, acc_knn_knn_imputer ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML model</th>\n",
       "      <th>Missing value handling technique</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI mean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI median</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI most frequent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI constant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>KNN Imputer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI mean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI median</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI most frequent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI constant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>KNN Imputer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI mean</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI median</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI most frequent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI constant</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNN Imputer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ML model Missing value handling technique  Accuracy\n",
       "0           Naive Bayes                          SI mean       NaN\n",
       "1           Naive Bayes                        SI median       NaN\n",
       "2           Naive Bayes                 SI most frequent       NaN\n",
       "3           Naive Bayes                      SI constant       NaN\n",
       "4           Naive Bayes                Iterative Imputer       NaN\n",
       "5           Naive Bayes                      KNN Imputer       NaN\n",
       "6   Logistic Regression                          SI mean       NaN\n",
       "7   Logistic Regression                        SI median       NaN\n",
       "8   Logistic Regression                 SI most frequent       NaN\n",
       "9   Logistic Regression                      SI constant       NaN\n",
       "10  Logistic Regression                Iterative Imputer       NaN\n",
       "11  Logistic Regression                      KNN Imputer       NaN\n",
       "12                  KNN                          SI mean       NaN\n",
       "13                  KNN                        SI median       NaN\n",
       "14                  KNN                 SI most frequent       NaN\n",
       "15                  KNN                      SI constant       NaN\n",
       "16                  KNN                Iterative Imputer       NaN\n",
       "17                  KNN                      KNN Imputer       NaN"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading a new csv file for introducing accuracy scores\n",
    "data = pd.read_csv('acc.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introducing accuracy scores\n",
    "for i in range(18):\n",
    "    data.loc[i, 'Accuracy'] = acc_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML model</th>\n",
       "      <th>Missing value handling technique</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI mean</td>\n",
       "      <td>0.927083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI median</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI most frequent</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>SI constant</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>KNN Imputer</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI mean</td>\n",
       "      <td>0.895833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI median</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI most frequent</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>SI constant</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>0.927083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>KNN Imputer</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI mean</td>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI median</td>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI most frequent</td>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KNN</td>\n",
       "      <td>SI constant</td>\n",
       "      <td>0.697917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Iterative Imputer</td>\n",
       "      <td>0.635417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KNN</td>\n",
       "      <td>KNN Imputer</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ML model Missing value handling technique  Accuracy\n",
       "0           Naive Bayes                          SI mean  0.927083\n",
       "1           Naive Bayes                        SI median  0.916667\n",
       "2           Naive Bayes                 SI most frequent  0.916667\n",
       "3           Naive Bayes                      SI constant  0.916667\n",
       "4           Naive Bayes                Iterative Imputer  0.937500\n",
       "5           Naive Bayes                      KNN Imputer  0.916667\n",
       "6   Logistic Regression                          SI mean  0.895833\n",
       "7   Logistic Regression                        SI median  0.885417\n",
       "8   Logistic Regression                 SI most frequent  0.885417\n",
       "9   Logistic Regression                      SI constant  0.885417\n",
       "10  Logistic Regression                Iterative Imputer  0.927083\n",
       "11  Logistic Regression                      KNN Imputer  0.885417\n",
       "12                  KNN                          SI mean  0.697917\n",
       "13                  KNN                        SI median  0.697917\n",
       "14                  KNN                 SI most frequent  0.697917\n",
       "15                  KNN                      SI constant  0.697917\n",
       "16                  KNN                Iterative Imputer  0.635417\n",
       "17                  KNN                      KNN Imputer  0.625000"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can observe that we have the highest accuracy score with Naive Bayes algorithm, no matter which handling technique we used\n",
    "## One exception is with Logistic Regression and Iterative imputer, as having 92% accuracy, this being higher than some of Naive Bayes scores\n",
    "## The lowest score was obtained with KNN algorithm and KNN Imputer - therefore they are not compatible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
